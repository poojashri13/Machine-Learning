height = 2
width = 3
ls()
area = height * width
area
ls()
area
is.*(height)
is.*()
poker_vector1 <- c(140, -50, 20, -120, 240)
names(poker_vector1) <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")
poker_vector2 <- c(Monday = 140, -50, 20, -120, 240)
roulette_vector1 <- c(-24, -50, 100, -350, 10)
days_vector <- names(poker_vector1)
names(roulette_vector1) <- days_vector
roulette_vector2 <- c(-24, -50, 100, -350, 10)
names(roulette_vector2) <- "Monday"
poker_vector1 <- c(140, -50, 20, -120, 240)
names(poker_vector1) <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")
poker_vector1
poker_vector2 <- c(Monday = 140, -50, 20, -120, 240)
poker_vector2
roulette_vector1 <- c(-24, -50, 100, -350, 10)
days_vector <- names(poker_vector1)
names(roulette_vector1) <- days_vector
roulette_vector1
roulette_vector2 <- c(-24, -50, 100, -350, 10)
names(roulette_vector2) <- "Monday"
roulette_vector2
poker_vector1 <- c(140, -50, 20, -120, 240)
names(poker_vector1) <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")
length(poker_vector1)
poker_vector2 <- c(Monday = 140, -50, 20, -120, 240)
length(poker_vector2)
roulette_vector1 <- c(-24, -50, 100, -350, 10)
days_vector <- names(poker_vector1)
names(roulette_vector1) <- days_vector
length(roulette_vector1)
roulette_vector2 <- c(-24, -50, 100, -350, 10)
names(roulette_vector2) <- "Monday"
length(roulette_vector2)
poker_vector <- c(140, -50, 20, -120, 240)
roulette_vector <- c(-24, -50, 100, -350, 10)
days_vector <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")
names(poker_vector) <- days_vector
names(roulette_vector) <- days_vector
# Select amounts for profitable roulette days: roulette_profits
roulette_profits <- roulette_vector[roulette_vector > 0]
# Sum of the profitable roulette days: roulette_total_profit
roulette_total_profit <- sum(roulette_profits)
# Number of profitable roulette days: num_profitable_days
num_profitable_days <- sum(roulette_vector>0)
num_profitable_days
x = c(1,2,3,4,5)
y = c(T,F,T,F,T)
x[y]
x = c(1,2,3,4,5)
y = c(T,F,T,F,T)
x[y]
order(y)
?sapply
install.packages("mlbench")
library(mlbench)
data(package = "mlbench")
data("PimaIndiansDiabetes")
head(PimaIndiansDiabetes)
data(iris)
summary(iris)
library(caret)
data(iris)
preprocess<-preprocess(iris[,1:4],method = c("range"))
preprocess<-preProcess(iris[,1:4],method = c("range"))
transformed<-predict(preprocess,iris[,1:4])
summary(transformed)
library(caret)
data("iris")
trainControl <- trainControl(method = "cv", number = 10)
fit <- train(Species~.,data=iris, trControl=trainControl,method = "nb")
library(e1071)
data("iris")
trainControl <- trainControl(method = "cv", number = 10)
fit <- train(Species~.,data=iris, trControl=trainControl,method = "nb")
install.packages(e1071)
install.packages("e1071")
trainControl <- trainControl(method = "cv", number = 10)
fit <- train(Species~.,data=iris, trControl=trainControl,method = "nb")
print(fit)
install.packages("rattle")
library(XML)
#Parse XML file
data <- xmlTreeParse("ProjectMSP.xml", useInternalNodes = T )
root=xmlRoot(data)
setwd("~/")
library(XML)
#Parse XML file
data <- xmlTreeParse("ProjectMSP.xml", useInternalNodes = T )
root=xmlRoot(data)
library(XML)
data <- xmlTreeParse("ProjectMSP.xml", useInternalNodes = T )
library(XML)
data <- xmlTreeParse("ProjectMSP.xml", useInternalNodes = T )
root=xmlRoot(data)
library(XML)
#Parse XML file
data <- xmlTreeParse("ProjectMSP.xml", useInternalNodes = T )
root=xmlRoot(data)
library(XML)
#Parse XML file
data <- xmlTreeParse("MSP.xml", useInternalNodes = T )
root=xmlRoot(data)
setwd("C:/Users/pshrivas/Machine Learning/Natural_Language_Processing/code")
dataset = read.delim("Restaurant_Review.tsv")
dataset = read.delim("Restaurant_Reviews.tsv")
View(dataset)
View(dataset)
dataset = read.delim("Restaurant_Reviews.tsv",quote = '')
dataset = read.delim("Restaurant_Reviews.tsv",quote = '', stringsAsFactors = F)
summary(dataset)
install.packages("tm")
library(tm)
corpus = VCorpus(VectorSource(dataset$Review))
as.character(corpus[[1]])
corpus = tm_map(corpus,content_transformer(tolower))
as.character(corpus[[1]])
corpus = tm_map(corpus,removeNumbers)
as.character(corpus[[841]])
corpus = tm_map(corpus,removePunctuation)
as.character(corpus[[841]])
as.character(corpus[[1]])
corpus = tm_map(corpus,removeWords, stopwords())
as.character(corpus[[1]])
install.packages("SnowballC")
library(SnowballC)
corpus = tm_map(corpus,removeWords, stopwords())
as.character(corpus[[1]])
corpus = tm_map(corpus,stemDocument)
as.character(corpus[[1]])
as.character(corpus[[841]])
corpus = tm_map(corpus, stripWhitespace)
as.character(corpus[[841]])
as.character(corpus[[1]])
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.99)
dtm
dtm = removeSparseTerms(dtm, 0.999)
dtm = removeSparseTerms(dtm, 0.999)
dtm
dtm = removeSparseTerms(dtm, 0.999)
#importing Dataset
dataset = read.delim("Restaurant_Reviews.tsv",quote = '', stringsAsFactors = F)
summary(dataset)
#Cleaning text
library(SnowballC)
library(tm)
corpus = VCorpus(VectorSource(dataset$Review))
corpus = tm_map(corpus,content_transformer(tolower))
corpus = tm_map(corpus,removeNumbers)
corpus = tm_map(corpus,removePunctuation)
corpus = tm_map(corpus,removeWords, stopwords())
corpus = tm_map(corpus,stemDocument)
corpus = tm_map(corpus, stripWhitespace)
#Creating Bag of Words model
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, 0.999)
dtm
X = as.data.frame(dtm)
X = as.data.frame(as.matrix(dtm))
dataset = as.data.frame(as.matrix(dtm))
View(X)
dataset_origina; = read.delim("Restaurant_Reviews.tsv",quote = '', stringsAsFactors = F)
dataset_original = read.delim("Restaurant_Reviews.tsv",quote = '', stringsAsFactors = F)
dataset$Liked = dataset_original$Liked
library(caTools)
set.seed(123)
split = sample.split(dataset$Liked, SplitRatio = 0.80)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
# Fitting SVM to the Training set
# install.packages('e1071')
library(e1071)
classifier = naiveBayes(x = training_set[-3],
y = training_set$Purchased)
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-3])
# Making the Confusion Matrix
cm = table(test_set[, 3], y_pred)
dataset$Liked = factor(dataset$Liked, levels=c(0,1))
